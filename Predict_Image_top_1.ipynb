{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/vishy/Desktop/Kaggle/Avito/Data/'\n",
    "subpath = '/home/vishy/Desktop//Kaggle/Avito/Submissions/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading train...\n",
      "loading test\n",
      "concat dfs\n"
     ]
    }
   ],
   "source": [
    "text_cols = ['param_1','param_2','param_3','title','description']\n",
    "print('loading train...')\n",
    "train = pd.read_csv(path+'train.csv', index_col = 'item_id', usecols = text_cols + ['item_id','image_top_1'])\n",
    "train_indices = train.index\n",
    "print('loading test')\n",
    "test = pd.read_csv(path+'test.csv', index_col = 'item_id', usecols = text_cols + ['item_id','image_top_1'])\n",
    "test_indices = test.index\n",
    "print('concat dfs')\n",
    "df = pd.concat([train,test])\n",
    "nan_indices = df[pd.isnull(df['image_top_1'])].index\n",
    "not_nan_indices = df[pd.notnull(df['image_top_1'])].index\n",
    "\n",
    "#df = df[pd.notnull(df['image_top_1'])]\n",
    "\n",
    "del train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2011862, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_1</th>\n",
       "      <th>param_2</th>\n",
       "      <th>param_3</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>image_top_1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>b912c3c6a6ad</th>\n",
       "      <td>Постельные принадлежности</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Кокоби(кокон для сна)</td>\n",
       "      <td>Кокон для сна малыша,пользовались меньше месяц...</td>\n",
       "      <td>1008.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2dac0150717d</th>\n",
       "      <td>Другое</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Стойка для Одежды</td>\n",
       "      <td>Стойка для одежды, под вешалки. С бутика.</td>\n",
       "      <td>692.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ba83aefab5dc</th>\n",
       "      <td>Видео, DVD и Blu-ray плееры</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Philips bluray</td>\n",
       "      <td>В хорошем состоянии, домашний кинотеатр с blu ...</td>\n",
       "      <td>3032.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>02996f1dd2ea</th>\n",
       "      <td>Автомобильные кресла</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Автокресло</td>\n",
       "      <td>Продам кресло от0-25кг</td>\n",
       "      <td>796.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7c90be56d2ab</th>\n",
       "      <td>С пробегом</td>\n",
       "      <td>ВАЗ (LADA)</td>\n",
       "      <td>2110</td>\n",
       "      <td>ВАЗ 2110, 2003</td>\n",
       "      <td>Все вопросы по телефону.</td>\n",
       "      <td>2264.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  param_1     param_2 param_3  \\\n",
       "item_id                                                         \n",
       "b912c3c6a6ad    Постельные принадлежности         NaN     NaN   \n",
       "2dac0150717d                       Другое         NaN     NaN   \n",
       "ba83aefab5dc  Видео, DVD и Blu-ray плееры         NaN     NaN   \n",
       "02996f1dd2ea         Автомобильные кресла         NaN     NaN   \n",
       "7c90be56d2ab                   С пробегом  ВАЗ (LADA)    2110   \n",
       "\n",
       "                              title  \\\n",
       "item_id                               \n",
       "b912c3c6a6ad  Кокоби(кокон для сна)   \n",
       "2dac0150717d      Стойка для Одежды   \n",
       "ba83aefab5dc         Philips bluray   \n",
       "02996f1dd2ea             Автокресло   \n",
       "7c90be56d2ab         ВАЗ 2110, 2003   \n",
       "\n",
       "                                                    description  image_top_1  \n",
       "item_id                                                                       \n",
       "b912c3c6a6ad  Кокон для сна малыша,пользовались меньше месяц...       1008.0  \n",
       "2dac0150717d          Стойка для одежды, под вешалки. С бутика.        692.0  \n",
       "ba83aefab5dc  В хорошем состоянии, домашний кинотеатр с blu ...       3032.0  \n",
       "02996f1dd2ea                             Продам кресло от0-25кг        796.0  \n",
       "7c90be56d2ab                           Все вопросы по телефону.       2264.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaning text\n",
      "concat text\n"
     ]
    }
   ],
   "source": [
    "print('cleaning text')\n",
    "for col in text_cols:\n",
    "    df[col] = df[col].fillna('nan').astype(str)\n",
    "print('concat text')\n",
    "df['text'] = df[text_cols].apply(lambda x: ' '.join(x), axis=1)\n",
    "df.drop(text_cols,axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_top_1</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>b912c3c6a6ad</th>\n",
       "      <td>1008.0</td>\n",
       "      <td>Постельные принадлежности nan nan Кокоби(кокон...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2dac0150717d</th>\n",
       "      <td>692.0</td>\n",
       "      <td>Другое nan nan Стойка для Одежды Стойка для од...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ba83aefab5dc</th>\n",
       "      <td>3032.0</td>\n",
       "      <td>Видео, DVD и Blu-ray плееры nan nan Philips bl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>02996f1dd2ea</th>\n",
       "      <td>796.0</td>\n",
       "      <td>Автомобильные кресла nan nan Автокресло Продам...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7c90be56d2ab</th>\n",
       "      <td>2264.0</td>\n",
       "      <td>С пробегом ВАЗ (LADA) 2110 ВАЗ 2110, 2003 Все ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              image_top_1                                               text\n",
       "item_id                                                                     \n",
       "b912c3c6a6ad       1008.0  Постельные принадлежности nan nan Кокоби(кокон...\n",
       "2dac0150717d        692.0  Другое nan nan Стойка для Одежды Стойка для од...\n",
       "ba83aefab5dc       3032.0  Видео, DVD и Blu-ray плееры nan nan Philips bl...\n",
       "02996f1dd2ea        796.0  Автомобильные кресла nan nan Автокресло Продам...\n",
       "7c90be56d2ab       2264.0  С пробегом ВАЗ (LADA) 2110 ВАЗ 2110, 2003 Все ..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vishy/anaconda3/envs/tensorflowenv/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizing...done. 76.29024243354797\n",
      "   Transforming text to seq...\n",
      "done. 63.28343439102173\n",
      "padding X_train\n",
      "done. 8.635580778121948\n",
      "padding X_nan\n",
      "done. 0.7657039165496826\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import text\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "max_features = 100000 # max amount of words considered\n",
    "max_len = 100 #maximum length of text\n",
    "dim = 100 #dimension of embedding\n",
    "\n",
    "\n",
    "print('tokenizing...',end='')\n",
    "tic = time.time()\n",
    "tokenizer = text.Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(list(df['text'].values))\n",
    "toc = time.time()\n",
    "print('done. {}'.format(toc-tic))\n",
    "\n",
    "col = 'text'\n",
    "print(\"   Transforming {} to seq...\".format(col))\n",
    "tic = time.time()\n",
    "df[col] = tokenizer.texts_to_sequences(df[col])\n",
    "toc = time.time()\n",
    "print('done. {}'.format(toc-tic))\n",
    "\n",
    "print('padding X_train')\n",
    "tic = time.time()\n",
    "X_train = pad_sequences(df.loc[not_nan_indices,col], maxlen=max_len)\n",
    "toc = time.time()\n",
    "print('done. {}'.format(toc-tic))\n",
    "\n",
    "print('padding X_nan')\n",
    "tic = time.time()\n",
    "X_nan = pad_sequences(df.loc[nan_indices,col], maxlen=max_len)\n",
    "toc = time.time()\n",
    "print('done. {}'.format(toc-tic))\n",
    "\n",
    "df.drop(['text'], axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.loc[not_nan_indices,'image_top_1'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 100)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 100, 100)     10000100    input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 100, 128)     63744       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_1 (Glo (None, 128)          0           bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_1 (GlobalM (None, 128)          0           bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 256)          0           global_average_pooling1d_1[0][0] \n",
      "                                                                 global_max_pooling1d_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 256)          1024        concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          65792       batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 3067)         788219      dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 10,918,879\n",
      "Trainable params: 10,918,367\n",
      "Non-trainable params: 512\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.layers import Input,PReLU,BatchNormalization, GlobalMaxPooling1D, GlobalAveragePooling1D, CuDNNGRU, Bidirectional, Dense, Embedding\n",
    "from keras.layers import Concatenate, Flatten, Bidirectional\n",
    "from keras.optimizers import Adam\n",
    "from keras.initializers import he_uniform\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "\n",
    "from keras.losses import categorical_crossentropy, sparse_categorical_crossentropy\n",
    "\n",
    "\n",
    "\n",
    "def all_pool(tensor):\n",
    "    avg_tensor = GlobalAveragePooling1D()(tensor)\n",
    "    max_tensor = GlobalMaxPooling1D()(tensor)\n",
    "    res_tensor = Concatenate()([avg_tensor, max_tensor])\n",
    "    return res_tensor\n",
    "\n",
    "def build_model():\n",
    "    inp = Input(shape=(max_len,))\n",
    "\n",
    "    embedding = Embedding(max_features + 1, dim)(inp)\n",
    "    x = Bidirectional(CuDNNGRU(64,return_sequences=True))(embedding)\n",
    "    x = all_pool(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dense(256, activation = 'relu')(x)\n",
    "    out = Dense(3067, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=inp, outputs=out)\n",
    "\n",
    "    model.compile(optimizer=Adam(lr=0.0005), loss=sparse_categorical_crossentropy)\n",
    "    return model\n",
    "\n",
    "model = build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1670998 samples, validate on 185667 samples\n",
      "Epoch 1/30\n",
      "1670998/1670998 [==============================] - 90s 54us/step - loss: 3.1640 - val_loss: 2.7277\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.72774, saving model to model.hdf5\n",
      "Epoch 2/30\n",
      "1670998/1670998 [==============================] - 86s 51us/step - loss: 2.5333 - val_loss: 2.6552\n",
      "\n",
      "Epoch 00002: val_loss improved from 2.72774 to 2.65520, saving model to model.hdf5\n",
      "Epoch 3/30\n",
      "1670998/1670998 [==============================] - 88s 53us/step - loss: 2.3603 - val_loss: 2.6726\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 2.65520\n",
      "Epoch 4/30\n",
      "1670998/1670998 [==============================] - 89s 53us/step - loss: 2.2133 - val_loss: 2.7640\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 2.65520\n",
      "Epoch 5/30\n",
      "1670998/1670998 [==============================] - 89s 53us/step - loss: 2.0738 - val_loss: 2.8253\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 2.65520\n",
      "Epoch 6/30\n",
      "1670998/1670998 [==============================] - 89s 53us/step - loss: 1.9403 - val_loss: 2.9423\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 2.65520\n",
      "Epoch 7/30\n",
      "1670998/1670998 [==============================] - 90s 54us/step - loss: 1.8158 - val_loss: 3.0794\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 2.65520\n"
     ]
    }
   ],
   "source": [
    "early_stop = EarlyStopping(patience=5)\n",
    "check_point = ModelCheckpoint('model.hdf5', monitor = \"val_loss\", mode = \"min\", save_best_only = True, verbose = 1)\n",
    "\n",
    "history = model.fit(X_train, y, batch_size = 512, epochs = 30, verbose = 1, validation_split=0.1,\n",
    "                    callbacks=[early_stop,check_point])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word = {tokenizer.word_index[word]:word for word in tokenizer.word_index}\n",
    "weights = model.layers[1].get_weights()[0]\n",
    "embedding_dict = {}\n",
    "for id in id2word:\n",
    "    if id <= weights.shape[0]-1:\n",
    "        embedding_dict[id2word[id]] = weights[id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('embedding_dict.p','wb') as f:\n",
    "    pickle.dump(embedding_dict,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "155197/155197 [==============================] - 25s 158us/step\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(X_nan,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 0\n",
    "classes = np.zeros(shape=np.argmax(preds,axis = 1).shape)\n",
    "for i in range(preds.shape[0]):\n",
    "    if np.max(preds[i]) > 0.1:\n",
    "        k+=1\n",
    "        classes[i] = np.argmax(preds[i])\n",
    "    else:\n",
    "        classes[i] = np.nan\n",
    "df.loc[nan_indices,'image_top_1'] = classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_top_1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>b912c3c6a6ad</th>\n",
       "      <td>1008.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2dac0150717d</th>\n",
       "      <td>692.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ba83aefab5dc</th>\n",
       "      <td>3032.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>02996f1dd2ea</th>\n",
       "      <td>796.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7c90be56d2ab</th>\n",
       "      <td>2264.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              image_top_1\n",
       "item_id                  \n",
       "b912c3c6a6ad       1008.0\n",
       "2dac0150717d        692.0\n",
       "ba83aefab5dc       3032.0\n",
       "02996f1dd2ea        796.0\n",
       "7c90be56d2ab       2264.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[train_indices].to_csv('train_image_top_1_features.csv')\n",
    "df.loc[test_indices].to_csv('test_image_top_1_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
