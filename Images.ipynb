{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from scipy.stats import itemfreq\n",
    "from scipy import ndimage as ndi\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import feature\n",
    "from PIL import Image as IMG\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import operator\n",
    "import cv2\n",
    "import os \n",
    "\n",
    "from IPython.core.display import HTML \n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_path = '/home/vishy/Desktop/Kaggle/Avito/Data/train_jpg/'\n",
    "imgs = os.listdir(train_images_path)\n",
    "features = pd.DataFrame()\n",
    "features['image'] = imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1390835, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>77582f51800ed0c9e99bfca0b7dd038f0d70c8f3cbed3b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f2a5a89b4fbed4a34ed831c96a06920ebfbdb9a2f1a9b6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1a1863a27f71c76463ee90ea4e6b5bff81c0726c0c92c4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cc3d6ed32168ada132cb8341b63a8c0b1d5ecd2fe7e27c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>805547905a5950b81b0f988b7b318989dd89968665564e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               image\n",
       "0  77582f51800ed0c9e99bfca0b7dd038f0d70c8f3cbed3b...\n",
       "1  f2a5a89b4fbed4a34ed831c96a06920ebfbdb9a2f1a9b6...\n",
       "2  1a1863a27f71c76463ee90ea4e6b5bff81c0726c0c92c4...\n",
       "3  cc3d6ed32168ada132cb8341b63a8c0b1d5ecd2fe7e27c...\n",
       "4  805547905a5950b81b0f988b7b318989dd89968665564e..."
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(features.shape)\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_analysis(img):\n",
    "    # obtain the color palatte of the image \n",
    "    palatte = defaultdict(int)\n",
    "    for pixel in img.getdata():\n",
    "        palatte[pixel] += 1\n",
    "    \n",
    "    # sort the colors present in the image \n",
    "    sorted_x = sorted(palatte.items(), key=operator.itemgetter(1), reverse = True)\n",
    "    light_shade, dark_shade, shade_count, pixel_limit = 0, 0, 0, 25\n",
    "    for i, x in enumerate(sorted_x[:pixel_limit]):\n",
    "        if all(xx <= 20 for xx in x[0][:3]): ## dull : too much darkness \n",
    "            dark_shade += x[1]\n",
    "        if all(xx >= 240 for xx in x[0][:3]): ## bright : too much whiteness \n",
    "            light_shade += x[1]\n",
    "        shade_count += x[1]\n",
    "        \n",
    "    light_percent = round((float(light_shade)/shade_count)*100, 2)\n",
    "    dark_percent = round((float(dark_shade)/shade_count)*100, 2)\n",
    "    return light_percent, dark_percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_color_analysis(img, flag):\n",
    "    path = train_images_path + img \n",
    "    im = IMG.open(path) #.convert(\"RGB\")\n",
    "    \n",
    "    # cut the images into two halves as complete average may give bias results\n",
    "    size = im.size\n",
    "    halves = (size[0]/2, size[1]/2)\n",
    "    im1 = im.crop((0, 0, size[0], halves[1]))\n",
    "    im2 = im.crop((0, halves[1], size[0], size[1]))\n",
    "\n",
    "    try:\n",
    "        light_percent1, dark_percent1 = color_analysis(im1)\n",
    "        light_percent2, dark_percent2 = color_analysis(im2)\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "    light_percent = (light_percent1 + light_percent2)/2 \n",
    "    dark_percent = (dark_percent1 + dark_percent2)/2 \n",
    "    \n",
    "    if flag == 'black':\n",
    "        return dark_percent\n",
    "    elif flag == 'white':\n",
    "        return light_percent\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-965dea626939>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dullness'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mperform_color_analysis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'black'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtopdull\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dullness'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mascending\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtopdull\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   2549\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2550\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masobject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2551\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2553\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/src/inference.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-965dea626939>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dullness'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mperform_color_analysis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'black'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtopdull\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dullness'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mascending\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtopdull\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-21-2da102f607bf>\u001b[0m in \u001b[0;36mperform_color_analysis\u001b[0;34m(img, flag)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mlight_percent1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdark_percent1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolor_analysis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mlight_percent2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdark_percent2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolor_analysis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-118fad4ce5e4>\u001b[0m in \u001b[0;36mcolor_analysis\u001b[0;34m(img)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# obtain the color palatte of the image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mpalatte\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mpixel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetdata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mpalatte\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpixel\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "features['dullness'] = features['image'].apply(lambda x : perform_color_analysis(x, 'black'))\n",
    "topdull = features.sort_values('dullness', ascending = False)\n",
    "topdull.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j,x in topdull.head(2).iterrows():\n",
    "    path = train_images_path + x['image']\n",
    "    html = \"<h4>Image : \"+x['image']+\" &nbsp;&nbsp;&nbsp; (Dullness : \" + str(x['dullness']) +\")</h4>\"\n",
    "    display(HTML(html))\n",
    "    display(IMG.open(path).resize((300,300), IMG.ANTIALIAS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features['whiteness'] = features['image'].apply(lambda x : perform_color_analysis(x, 'white'))\n",
    "topdull = features.sort_values('whiteness', ascending = False)\n",
    "topdull.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j,x in topdull.head(2).iterrows():\n",
    "    path = train_images_path + x['image']\n",
    "    html = \"<h4>Image : \"+x['image']+\" &nbsp;&nbsp;&nbsp; (Whiteness : \" + str(x['whiteness']) +\")</h4>\"\n",
    "    display(HTML(html))\n",
    "    display(IMG.open(path).resize((300,300), IMG.ANTIALIAS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im1 = IMG.open(train_images_path+'59.png')\n",
    "im2 = im1.convert(mode='L')\n",
    "im = np.asarray(im2)\n",
    "\n",
    "edges1 = feature.canny(im, sigma=1)\n",
    "edges2 = feature.canny(im, sigma=3)\n",
    "\n",
    "# display results\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(nrows=1, ncols=3, figsize=(8, 3), sharex=True, sharey=True)\n",
    "\n",
    "ax1.imshow(im, cmap=plt.cm.gray)\n",
    "ax1.axis('off')\n",
    "ax1.set_title('noisy image', fontsize=20)\n",
    "\n",
    "ax2.imshow(edges1, cmap=plt.cm.gray)\n",
    "ax2.axis('off')\n",
    "ax2.set_title('Canny filter, $\\sigma=1$', fontsize=20)\n",
    "\n",
    "ax3.imshow(edges2, cmap=plt.cm.gray)\n",
    "ax3.axis('off')\n",
    "ax3.set_title('Canny filter, $\\sigma=3$', fontsize=20)\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_pixel_width(img):\n",
    "    path = train_images_path + img \n",
    "    im = IMG.open(path)    \n",
    "    im_array = np.asarray(im.convert(mode='L'))\n",
    "    edges_sigma1 = feature.canny(im_array, sigma=3)\n",
    "    apw = (float(np.sum(edges_sigma1)) / (im.size[0]*im.size[1]))\n",
    "    return apw*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features['average_pixel_width'] = features['image'].apply(average_pixel_width)\n",
    "tempdf = features.sort_values('average_pixel_width').head()\n",
    "tempdf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j,x in tempdf.head(6).iterrows():\n",
    "    path = train_images_path + x['image']\n",
    "    html = \"<h4>Image : \"+x['image']+\" &nbsp;&nbsp;&nbsp; (Average Pixel Width : \" + str(x['average_pixel_width']) +\")</h4>\"\n",
    "    display(HTML(html))\n",
    "    display(IMG.open(path).resize((300,300), IMG.ANTIALIAS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dominant_color(img):\n",
    "    path = train_images_path + img \n",
    "    img = cv2.imread(path)\n",
    "    arr = np.float32(img)\n",
    "    pixels = arr.reshape((-1, 3))\n",
    "\n",
    "    n_colors = 5\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 200, .1)\n",
    "    flags = cv2.KMEANS_RANDOM_CENTERS\n",
    "    _, labels, centroids = cv2.kmeans(pixels, n_colors, None, criteria, 10, flags)\n",
    "\n",
    "    palette = np.uint8(centroids)\n",
    "    quantized = palette[labels.flatten()]\n",
    "    quantized = quantized.reshape(img.shape)\n",
    "\n",
    "    dominant_color = palette[np.argmax(itemfreq(labels)[:, -1])]\n",
    "    return dominant_color\n",
    "\n",
    "features['dominant_color'] = features['image'].apply(get_dominant_color)\n",
    "features.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features['dominant_red'] = features['dominant_color'].apply(lambda x: x[0]) / 255\n",
    "features['dominant_green'] = features['dominant_color'].apply(lambda x: x[1]) / 255\n",
    "features['dominant_blue'] = features['dominant_color'].apply(lambda x: x[2]) / 255\n",
    "features[['dominant_red', 'dominant_green', 'dominant_blue']].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_color(img):\n",
    "    path = train_images_path + img \n",
    "    img = cv2.imread(path)\n",
    "    average_color = [img[:, :, i].mean() for i in range(img.shape[-1])]\n",
    "    return average_color\n",
    "\n",
    "features['average_color'] = features['image'].apply(get_average_color)\n",
    "features.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features['average_red'] = features['average_color'].apply(lambda x: x[0]) / 255\n",
    "features['average_green'] = features['average_color'].apply(lambda x: x[1]) / 255\n",
    "features['average_blue'] = features['average_color'].apply(lambda x: x[2]) / 255\n",
    "features[['average_red', 'average_green', 'average_blue']].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSize(filename):\n",
    "    filename = train_images_path + filename\n",
    "    st = os.stat(filename)\n",
    "    return st.st_size\n",
    "\n",
    "def getDimensions(filename):\n",
    "    filename = train_images_path + filename\n",
    "    img_size = IMG.open(filename).size\n",
    "    return img_size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features['image_size'] = features['image'].apply(getSize)\n",
    "features['temp_size'] = features['image'].apply(getDimensions)\n",
    "features['width'] = features['temp_size'].apply(lambda x : x[0])\n",
    "features['height'] = features['temp_size'].apply(lambda x : x[1])\n",
    "features = features.drop(['temp_size', 'average_color', 'dominant_color'], axis=1)\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_blurrness_score(image):\n",
    "    path =  train_images_path + image \n",
    "    image = cv2.imread(path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    fm = cv2.Laplacian(image, cv2.CV_64F).var()\n",
    "    return fm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features['blurrness'] = features['image'].apply(get_blurrness_score)\n",
    "features[['image','blurrness']].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempdf = features.sort_values('blurrness')\n",
    "for y,x in tempdf.head(5).iterrows():\n",
    "    path = images_path + x['image']\n",
    "    html = \"<h4>Image : \"+x['image']+\" &nbsp;&nbsp;&nbsp; (Blurrness : \" + str(x['blurrness']) +\")</h4>\"\n",
    "    display(HTML(html))\n",
    "    display(IMG.open(path).resize((300,300), IMG.ANTIALIAS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Classification with Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
